# Phase 4: Simulation Engine (EC2)

**Status:** ✅ COMPLETE
**Prerequisites:** Phase 2 & 3 complete (RDS populated with 6.7M plays)
**Actual Time:** 3 hours
**Actual Cost:** $6.59/month (t3.small 8hrs/day)
**Started:** October 3, 2025
**Completed:** October 3, 2025

---

> **⚠️ IMPORTANT - Before Starting This Phase:**
>
> **Ask Claude:** "Should I add any workflows to this phase before beginning?"
>
> This allows Claude to review the current workflow references and recommend any missing workflows that would improve implementation guidance. Phases 1-3 were enhanced with comprehensive workflow instructions - this phase should receive the same treatment before starting work.

---

## Overview

Set up AWS EC2 instance to run NBA game simulations using historical data from RDS PostgreSQL. The simulation engine will use Monte Carlo methods and statistical models to predict game outcomes based on team/player performance patterns.

**⚠️ Temporal Enhancement Opportunity:**
This phase can be enhanced with temporal simulation capabilities once 3.0005 (Temporal Database Schema) is complete. Temporal simulation enables event-level resolution with precise timestamps, player aging effects, and fatigue modeling.

**💡 Possession Panel Data Source Options:**
For creating possession-level panel data (required for advanced simulation), we have two approaches:

1. **Custom Implementation** (Current approach)
   - Full control over possession detection logic
   - Integration with multiple data sources (Kaggle, NBA API, ESPN)
   - Scripts: `scripts/etl/create_possession_panel_from_*.py`
   - Status: 3 implementations built (Kaggle: 127 poss/game, NBA API: 235 poss/game, ESPN: TBD)

2. **pbpstats Library** (Alternative - Recommended for future enhancements)
   - Production-tested lineup tracking + possession parsing
   - **Time savings:** 4-6 weeks development vs custom
   - **Best for:** When lineup tracking is needed (who's on court)
   - **See:** `docs/analysis/PBPSTATS_EVALUATION.md` for detailed analysis
   - **Recommendation:** Hybrid approach (pbpstats base + custom enrichment)

**This phase includes:**
- EC2 instance provisioning
- Python 3.11 + dependencies installation
- Simulation code deployment (traditional game-level)
- RDS connection from EC2
- Test simulation execution
- **(Future)** Temporal event-level simulation

---

## Prerequisites

Before starting this phase:
- [ ] Phase 2 complete (data loaded to RDS)
- [ ] Phase 3 complete (RDS operational with 6.7M plays)
- [ ] Simulation code developed (Python scripts)
- [ ] SSH key pair created or available

**Follow these workflows before beginning:**

- Workflow #1 ([Session Start](../claude_workflows/workflow_descriptions/01_session_start.md))
  - **When to run:** At the very beginning of working on Phase 4
  - **Purpose:** Initialize session, check environment, review what was completed last session

- Workflow #34 ([Lessons Learned Review](../claude_workflows/workflow_descriptions/34_lessons_learned_review.md))
  - **When to run:** After session start, before making any decisions
  - **Purpose:** Review LESSONS_LEARNED.md for EC2-related lessons from previous phases

- Workflow #3 ([Decision Workflow](../claude_workflows/workflow_descriptions/03_decision_workflow.md))
  - **When to run:** When making major Phase 4 decisions (EC2 instance type, simulation architecture)
  - **Purpose:** Document key architectural decisions as ADRs before implementing

**See workflow #24 (AWS Resource Setup) for EC2 provisioning.**

---

## What Actually Happened (October 3, 2025)

**Actual execution details from completed implementation:**

### Key Decisions Made
1. **No pre-written simulation code:** Developed simulation scripts from scratch during phase
2. **SSH key created fresh:** No existing key pair - created `nba-simulator-ec2-key`
3. **Used t3.small 8hrs/day:** Final cost: $6.59/month ($4.99 compute + $1.60 storage)
4. **Created Workflow #37:** New workflow for credential management (added to system)

### Actual Steps Executed

**1. Prerequisites (15 min)**
- Followed Workflow #1 (Session Start) ✅
- Followed Workflow #34 (Lessons Learned Review) - found security group lessons ✅
- Followed Workflow #18 (Cost Management) - approved $6.59/month ✅

**2. SSH Key Creation (5 min)**
```bash
aws ec2 create-key-pair --key-name nba-simulator-ec2-key --query 'KeyMaterial' --output text > ~/.ssh/nba-simulator-ec2-key.pem
chmod 400 ~/.ssh/nba-simulator-ec2-key.pem
# Result: Successfully created and secured
```

**3. Security Group Creation (5 min)**
```bash
# Get current IP
MY_IP=$(curl -s https://checkip.amazonaws.com)

# Create security group
aws ec2 create-security-group --group-name nba-ec2-sg --description "SSH access for NBA simulator EC2"
# Result: sg-0b9ca09f4a041e1c8

# Add SSH rule
aws ec2 authorize-security-group-ingress --group-id sg-0b9ca09f4a041e1c8 --protocol tcp --port 22 --cidr ${MY_IP}/32
```

**4. EC2 Instance Launch (10 min)**
```bash
# Get latest Amazon Linux 2023 AMI
AMI_ID=$(aws ec2 describe-images --owners amazon --filters "Name=name,Values=al2023-ami-2023.*-x86_64" --query 'Images | sort_by(@, &CreationDate) | [-1].ImageId' --output text)
# Result: ami-052064a798f08f0d3

# Launch instance
aws ec2 run-instances --image-id ami-052064a798f08f0d3 --instance-type t3.small --key-name nba-simulator-ec2-key --security-group-ids sg-0b9ca09f4a041e1c8 --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=nba-simulation-engine}]'
# Result: i-0b8bbe4cdff7ae2d2

# Wait for running state
aws ec2 wait instance-running --instance-ids i-0b8bbe4cdff7ae2d2

# Get public IP
aws ec2 describe-instances --instance-ids i-0b8bbe4cdff7ae2d2 --query 'Reservations[0].Instances[0].PublicIpAddress' --output text
# Result: 54.165.99.80
```

**5. Software Installation (20 min)**
```bash
# SSH into instance
ssh -i ~/.ssh/nba-simulator-ec2-key.pem ec2-user@54.165.99.80

# Update system
sudo yum update -y

# Install Python 3.11, PostgreSQL client, git
sudo yum install python3.11 python3.11-pip git postgresql15 -y

# Install Python packages (use --user flag)
pip3.11 install boto3 pandas psycopg2-binary sqlalchemy numpy scipy --user

# Verify versions
python3.11 --version  # Python 3.11.13
psql --version        # PostgreSQL 15.14
pip3.11 list | grep -E "boto3|pandas|psycopg2"
# boto3 1.40.44, pandas 2.3.3, psycopg2-binary 2.9.10, numpy 2.3.3, scipy 1.16.2
```

**6. RDS Security Group Update (5 min)**
```bash
# Add EC2 security group to RDS ingress rules
aws ec2 authorize-security-group-ingress --group-id sg-079ed470e0caaca44 --protocol tcp --port 5432 --source-group sg-0b9ca09f4a041e1c8
# Result: EC2 can now connect to RDS
```

**7. Environment Configuration (10 min)**
```bash
# Create ~/.env file on EC2
cat > ~/.env << 'EOF'
DB_HOST=nba-sim-db.ck96ciigs7fy.us-east-1.rds.amazonaws.com
DB_PORT=5432
DB_NAME=nba_simulator
DB_USER=postgres
DB_PASSWORD=NbaSimulator2025!SecurePass
AWS_REGION=us-east-1
EOF

chmod 600 ~/.env

# Add auto-load to .bashrc
echo "if [ -f ~/.env ]; then source ~/.env; fi" >> ~/.bashrc

# Test psql connection
source ~/.env
PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -U $DB_USER -d $DB_NAME -c "SELECT COUNT(*) FROM games;"
# Result: 44,828 ✅

# Test Python connection
python3.11 -c "import psycopg2; conn = psycopg2.connect(host='nba-sim-db.ck96ciigs7fy.us-east-1.rds.amazonaws.com', database='nba_simulator', user='postgres', password='NbaSimulator2025!SecurePass'); cur = conn.cursor(); cur.execute('SELECT COUNT(*) FROM play_by_play'); print(f'Rows: {cur.fetchone()[0]:,}'); conn.close()"
# Result: Rows: 6,781,155 ✅
```

**8. Simulation Code Development (60 min)**

Created directory structure:
```bash
mkdir -p ~/nba-simulation/{scripts,data,results}
```

**Created files:**

`~/nba-simulation/scripts/db_connection.py` (120 lines)
- NBADatabase class with connection pooling
- Methods: `get_team_stats()`, `get_head_to_head()`, `get_recent_games()`
- **Important fix:** Used correct column names from actual schema:
  - `home_team_abbrev`, `away_team_abbrev` (NOT home_team_abbreviation)
  - `home_score`, `away_score` (verified with `\d games`)
  - `home_team_is_winner`, `away_team_is_winner`

`~/nba-simulation/scripts/simulate_game.py` (200+ lines)
- GameSimulator class with Monte Carlo methods
- Normal distribution scoring model
- Command-line interface with argparse
- CSV result export
- **Key parameters:**
  - Home advantage: +3.0 points
  - Standard deviation: 12.0 points
  - Default iterations: 1000

`~/nba-simulation/README.md` (3.9 KB)
- Complete documentation of simulation methodology
- Usage examples
- Database schema reference
- Performance benchmarks

**9. Testing & Validation (20 min)**
```bash
cd ~/nba-simulation/scripts

# Test 1: Lakers vs Celtics (1,000 iterations)
python3.11 simulate_game.py --home-team LAL --away-team BOS --iterations 1000
# Result: LAL 54.1% win prob, predicted 106.4-104.1 ✅

# Test 2: Warriors vs Heat (5,000 iterations)
python3.11 simulate_game.py --home-team GSW --away-team MIA --iterations 5000 --season 2022-23
# Result: GSW 58.1% win prob, predicted 107.8-103.4 ✅

# Performance: 5,000 iterations completed in ~5-8 seconds ✅
```

**10. Credential Management (15 min)**

**Created Workflow #37:** `/Users/ryanranft/nba-simulator-aws/docs/claude_workflows/workflow_descriptions/37_credential_management.md`

Updated `/Users/ryanranft/nba-sim-credentials.env`:
```bash
# ============================================================================
# EC2 Configuration (Phase 4 - Simulation Engine)
# ============================================================================
export EC2_INSTANCE_ID="i-0b8bbe4cdff7ae2d2"
export EC2_PUBLIC_IP="54.165.99.80"
export EC2_INSTANCE_TYPE="t3.small"
export EC2_KEY_NAME="nba-simulator-ec2-key"
export EC2_KEY_PATH="/Users/ryanranft/.ssh/nba-simulator-ec2-key.pem"
export EC2_SECURITY_GROUP_ID="sg-0b9ca09f4a041e1c8"
export EC2_SSH_USER="ec2-user"
```

### Critical Insights

**What worked well:**
1. ✅ AWS CLI automation for all infrastructure (no console usage)
2. ✅ Security group source-group reference (EC2 → RDS) instead of IP ranges
3. ✅ `--user` flag for pip install (avoids permission issues)
4. ✅ Auto-load ~/.env in .bashrc (persistent environment)
5. ✅ Checking table schema first (`\d games`, `\d play_by_play`)

**What didn't work initially:**
1. ❌ Python connection using environment variables in heredoc (variables not passed)
   - **Fix:** Use explicit credentials or pass variables differently
2. ❌ Wrong column names (homedescription, visitordescription)
   - **Fix:** Queried actual schema with `\d table_name`
3. ❌ pandas warnings about psycopg2 connection
   - **Solution:** Warnings are cosmetic, can ignore or use SQLAlchemy in future

**Lessons for Phase 5:**
1. Always check database schema before writing queries
2. Use `aws ec2 wait` commands for instance state changes
3. Security groups are better with source-group references than IP ranges
4. Test database connections with both psql AND Python before deploying code
5. Document all resource IDs immediately (instance ID, security group IDs)

### Actual Resource IDs
- **EC2 Instance:** i-0b8bbe4cdff7ae2d2
- **EC2 Public IP:** 54.165.99.80 (changes on restart!)
- **EC2 Security Group:** sg-0b9ca09f4a041e1c8
- **RDS Security Group:** sg-079ed470e0caaca44
- **SSH Key:** ~/.ssh/nba-simulator-ec2-key.pem (400 permissions)
- **AMI Used:** ami-052064a798f08f0d3 (Amazon Linux 2023)

### Actual Time Breakdown
- Setup & prerequisites: 35 min
- Infrastructure provisioning: 20 min
- Software installation: 20 min
- Database configuration: 15 min
- Code development: 60 min
- Testing & validation: 20 min
- Documentation: 30 min
- **Total: ~3 hours** (matches estimate!)

---

## Implementation Steps

### Sub-4.0001: EC2 Instance Launch

**Status:** ✅ COMPLETE
**Time Estimate:** 30 minutes
**Cost:** $5-15/month

**Follow these workflows:**
- Workflow #18 ([Cost Management](../claude_workflows/workflow_descriptions/18_cost_management.md))
  - **When to run:** BEFORE launching EC2 instance
  - **Purpose:** Estimate monthly costs ($5-15/month based on usage), get user approval
  - **Key decision:** t3.small on-demand vs spot instance vs 8hrs/day vs 24/7

- Workflow #34 ([Lessons Learned Review](../claude_workflows/workflow_descriptions/34_lessons_learned_review.md))
  - **When to run:** Before EC2 provisioning
  - **Purpose:** Check if any EC2-related lessons exist in LESSONS_LEARNED.md

- Workflow #24 ([AWS Resource Setup](../claude_workflows/workflow_descriptions/24_aws_resource_setup.md))
  - **When to run:** When launching EC2 instance
  - **Purpose:** Follow EC2 best practices (AMI selection, security group setup, SSH key management)

- Workflow #2 ([Command Logging](../claude_workflows/workflow_descriptions/02_command_logging.md))
  - **When to run:** After running AWS CLI commands
  - **Purpose:** Log EC2 launch commands to COMMAND_LOG.md for future reference

- Workflow #11 ([Error Handling](../claude_workflows/workflow_descriptions/11_error_handling.md))
  - **When to run:** If EC2 launch fails
  - **Purpose:** Troubleshoot instance launch issues, security group problems, SSH connection failures

- Workflow #28 ([ADR Creation](../claude_workflows/workflow_descriptions/28_adr_creation.md))
  - **When to run:** After making instance type or configuration decisions
  - **Purpose:** Document architectural decisions (instance type, spot vs on-demand, usage schedule)

**Configuration:**
1. [ ] Launch EC2 instance via AWS Console
2. [ ] Configure security group for SSH access
3. [ ] Connect via SSH and verify
4. [ ] Document instance details

**Recommended configuration:**
- **AMI:** Amazon Linux 2023 (free tier eligible)
- **Instance type:** t3.small
- **vCPUs:** 2
- **RAM:** 2 GB
- **Storage:** 20 GB GP3
- **Key pair:** Select existing or create new
- **Security group:** Allow SSH (port 22) from your IP

**Launch command (CLI alternative):**
```bash
aws ec2 run-instances \
  --image-id ami-xxxxxxxxx \
  --instance-type t3.small \
  --key-name your-key-pair \
  --security-group-ids sg-xxxxxxxxx \
  --subnet-id subnet-xxxxxxxxx \
  --block-device-mappings '[{"DeviceName":"/dev/xvda","Ebs":{"VolumeSize":20,"VolumeType":"gp3"}}]' \
  --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=nba-simulation-engine}]'
```

**Validation:**
- [ ] Instance status: Running
- [ ] Public IP assigned
- [ ] SSH connection successful

---

### Sub-4.0002: Software Installation

**Status:** ⏸️ PENDING
**Time Estimate:** 1 hour

**Follow these workflows:**
- Workflow #17 ([Environment Setup](../claude_workflows/workflow_descriptions/17_environment_setup.md))
  - **When to run:** After connecting to EC2 instance
  - **Purpose:** Verify Python 3.11 installation, set up environment correctly on EC2

- Workflow #2 ([Command Logging](../claude_workflows/workflow_descriptions/02_command_logging.md))
  - **When to run:** After running installation commands
  - **Purpose:** Log installation commands to COMMAND_LOG.md for reproducibility

**Installation steps:**
1. [ ] Connect to EC2 instance via SSH
2. [ ] Update system packages
3. [ ] Install Python 3.11
4. [ ] Install PostgreSQL client
5. [ ] Install Python packages
6. [ ] Verify installations

**Commands to execute:**
```bash
# Connect to instance
ssh -i your-key.pem ec2-user@ec2-xx-xx-xx-xx.compute-1.amazonaws.com

# Update system
sudo yum update -y

# Install Python 3.11
sudo yum install python3.11 python3.11-pip git -y

# Install PostgreSQL client
sudo yum install postgresql15 -y

# Install Python packages
pip3.11 install boto3 pandas psycopg2-binary sqlalchemy numpy scipy

# Verify installations
python3.11 --version
# Expected: Python 3.11.x

psql --version
# Expected: psql (PostgreSQL) 15.x

pip3.11 list | grep -E "boto3|pandas|psycopg2|sqlalchemy|numpy"
```

**Validation:**
- [ ] Python 3.11 installed
- [ ] PostgreSQL client installed
- [ ] All required packages installed
- [ ] No dependency errors

---

### Sub-4.0003: Environment Configuration

**Status:** ⏸️ PENDING
**Time Estimate:** 15 minutes

**Follow these workflows:**
- Workflow #32 ([RDS Connection](../claude_workflows/workflow_descriptions/32_rds_connection.md))
  - **When to run:** Before testing database connection from EC2
  - **Purpose:** Verify RDS security group allows EC2, test connection methods

- Workflow #23 ([Credential Rotation](../claude_workflows/workflow_descriptions/23_credential_rotation.md))
  - **When to run:** After creating ~/.env file with database credentials
  - **Purpose:** Ensure ~/.env has proper permissions (600), document credential location

- Workflow #16 ([Testing](../claude_workflows/workflow_descriptions/16_testing.md))
  - **When to run:** After environment configuration
  - **Purpose:** Test database connection with sample queries, verify row counts

**Configuration steps:**
1. [ ] Create environment variables file
2. [ ] Set RDS connection details
3. [ ] Load environment variables
4. [ ] Test database connection

**Create ~/.env file:**
```bash
cat > ~/.env << 'EOF'
DB_HOST=nba-sim-db.ck96ciigs7fy.us-east-1.rds.amazonaws.com
DB_PORT=5432
DB_NAME=nba_simulator
DB_USER=postgres
DB_PASSWORD=your_password_here
AWS_REGION=us-east-1
EOF

# Set permissions
chmod 600 ~/.env

# Load variables
source ~/.env
```

**Test connection:**
```bash
# Test psql connection
psql -h $DB_HOST -U $DB_USER -d $DB_NAME -c "SELECT COUNT(*) FROM games;"
# Expected: 44,828

# Test Python connection
python3.11 << 'EOF'
import psycopg2
import os

conn = psycopg2.connect(
    host=os.getenv('DB_HOST'),
    database=os.getenv('DB_NAME'),
    user=os.getenv('DB_USER'),
    password=os.getenv('DB_PASSWORD')
)
cursor = conn.cursor()
cursor.execute("SELECT COUNT(*) FROM play_by_play;")
print(f"Play-by-play rows: {cursor.fetchone()[0]:,}")
conn.close()
EOF
# Expected: Play-by-play rows: 6,781,155
```

**Validation:**
- [ ] Environment variables set
- [ ] psql connection successful
- [ ] Python connection successful
- [ ] Can query all tables

---

### Sub-4.0004: Simulation Code Deployment

**Status:** ⏸️ PENDING
**Time Estimate:** 30 minutes

**Follow these workflows:**
- Workflow #6 ([File Creation](../claude_workflows/workflow_descriptions/06_file_creation.md))
  - **When to run:** When creating new simulation script files
  - **Purpose:** Follow file creation best practices, ensure proper structure and documentation

- Workflow #27 ([TDD Workflow](../claude_workflows/workflow_descriptions/27_tdd_workflow.md))
  - **When to run:** Before writing simulation code (if not already written)
  - **Purpose:** Write tests first for simulation logic, Monte Carlo methods

- Workflow #16 ([Testing](../claude_workflows/workflow_descriptions/16_testing.md))
  - **When to run:** After deploying simulation code to EC2
  - **Purpose:** Run test simulation, verify results are reasonable, test query performance

- Workflow #35 ([Pre-Deployment Testing](../claude_workflows/workflow_descriptions/35_pre_deployment_testing.md))
  - **When to run:** Before running full-scale simulations
  - **Purpose:** Phase-specific testing checklist for Phase 4 (simulation engine validation)

- Workflow #30 ([Code Snippet Logging](../claude_workflows/workflow_descriptions/30_code_snippet_logging.md))
  - **When to run:** After writing simulation code
  - **Purpose:** Log simulation algorithms and outcomes to COMMAND_LOG.md

- Workflow #08 ([Git Commit](../claude_workflows/workflow_descriptions/08_git_commit.md))
  - **When to run:** After deploying and testing simulation code
  - **Purpose:** Commit simulation scripts with proper security scanning, version control

- Workflow #10 ([Git Push](../claude_workflows/workflow_descriptions/10_git_push.md))
  - **When to run:** After committing simulation code
  - **Purpose:** Push simulation code to remote repository with pre-push inspection

- Workflow #14 ([Session End](../claude_workflows/workflow_descriptions/14_session_end.md))
  - **When to run:** After completing Phase 4
  - **Purpose:** Properly end session, update documentation, prepare for next session

**Deployment steps:**
1. [ ] Clone repository to EC2 (or upload code)
2. [ ] Verify simulation scripts
3. [ ] Run test simulation
4. [ ] Document results

**Clone repository:**
```bash
# If using Git
git clone git@github.com:ryanranft/nba-simulator-aws.git
cd nba-simulator-aws

# Or upload specific files via SCP
scp -i your-key.pem scripts/simulation/*.py ec2-user@ec2-xx-xx-xx-xx:~/
```

**Run test simulation:**
```bash
# Example: Simulate Lakers vs Celtics
python3.11 scripts/simulation/simulate_game.py \
  --home-team LAL \
  --away-team BOS \
  --iterations 1000

# Expected output:
# Lakers win probability: 52.3%
# Celtics win probability: 47.7%
# Average score: LAL 108.5 - BOS 106.2
```

**Validation:**
- [ ] Code uploaded successfully
- [ ] Test simulation runs without errors
- [ ] Results are reasonable (based on historical data)
- [ ] Query performance acceptable (<5 seconds)

---

## Cost Breakdown

| Resource | Configuration | Monthly Cost | Notes |
|----------|--------------|--------------|-------|
| **Option A: t3.small (Recommended)** | | | |
| Compute (8 hrs/day) | 2 vCPUs, 2 GB RAM | $4.99 | $0.0208/hr × 240 hrs |
| Compute (24/7) | 2 vCPUs, 2 GB RAM | $15.18 | $0.0208/hr × 730 hrs |
| Storage | 20 GB GP3 | $1.60 | Always charged |
| **Total (8 hrs/day)** | | **~$7/month** | Start/stop as needed |
| **Total (24/7)** | | **~$17/month** | Always running |
| | | | |
| **Option B: t3.micro (Minimal)** | | | |
| Compute (4 hrs/day) | 2 vCPUs, 1 GB RAM | $1.25 | $0.0104/hr × 120 hrs |
| Storage | 20 GB GP3 | $1.60 | Always charged |
| **Total (4 hrs/day)** | | **~$3/month** | Testing only |
| | | | |
| **Option C: Spot Instance t3.small** | | | |
| Compute (24/7) | 2 vCPUs, 2 GB RAM | $4.40 | ~$0.006/hr (70% discount) |
| Storage | 20 GB GP3 | $1.60 | Always charged |
| **Total (24/7)** | | **~$6/month** | Can be interrupted |

**Recommendation:** t3.small on-demand, start when needed, stop when idle = **$5-10/month**

---

## Instance Management

**Start/Stop Commands:**

```bash
# Stop instance when not in use (stops compute billing)
aws ec2 stop-instances --instance-ids i-xxxxxxxxx

# Start instance when needed
aws ec2 start-instances --instance-ids i-xxxxxxxxx

# Get public IP after start (IP changes on restart)
aws ec2 describe-instances \
  --instance-ids i-xxxxxxxxx \
  --query 'Reservations[0].Instances[0].PublicIpAddress' \
  --output text

# Check instance status
aws ec2 describe-instances \
  --instance-ids i-xxxxxxxxx \
  --query 'Reservations[0].Instances[0].State.Name' \
  --output text
```

**Cost optimization:**
- Stop instance when not in use (saves compute costs)
- Storage costs continue even when stopped ($1.60/month)
- Public IP changes on restart (document new IP each time)

---

## Simulation Workflows

**Typical simulation tasks:**

1. **Single game simulation:**
   ```bash
   python3.11 scripts/simulation/simulate_game.py \
     --home-team LAL --away-team BOS --iterations 1000
   ```

2. **Playoff series simulation:**
   ```bash
   python3.11 scripts/simulation/simulate_series.py \
     --team1 LAL --team2 BOS --series-format "2-2-1-1-1"
   ```

3. **Season prediction:**
   ```bash
   python3.11 scripts/simulation/simulate_season.py \
     --season 2024-25 --iterations 10000
   ```

4. **Player impact analysis:**
   ```bash
   python3.11 scripts/simulation/player_impact.py \
     --player "LeBron James" --games 82
   ```

---

## Troubleshooting

**Common issues:**

1. **SSH connection refused**
   - Check security group allows port 22 from your IP
   - Verify instance is running
   - Use correct key pair (.pem file)

2. **Database connection timeout**
   - RDS security group must allow EC2 security group
   - Or allow EC2's IP range
   - See workflow #32 for connection troubleshooting

3. **Python package installation fails**
   - Run `sudo yum install python3.11-devel` first
   - PostgreSQL dev libraries: `sudo yum install postgresql-devel`

4. **Out of memory during simulation**
   - Reduce iteration count
   - Or upgrade to t3.medium (4 GB RAM)

---

## Success Criteria

Phase complete when:
- [ ] EC2 instance running
- [ ] Python 3.11 + all dependencies installed
- [ ] Database connection from EC2 verified
- [ ] Test simulation runs successfully
- [ ] Results are reasonable and reproducible
- [ ] Query performance acceptable (<5 seconds)
- [ ] Cost within budget ($5-15/month)
- [ ] Start/stop procedures documented

---

## Next Steps

After completing this phase:
1. [ ] Update PROGRESS.md status
2. [ ] Document simulation results
3. [ ] Proceed to [Phase 5: Machine Learning](PHASE_5_MACHINE_LEARNING.md)

**Note:** Phase 4 and Phase 5 can run in parallel if desired (both depend on RDS data).

---

## Security Best Practices

**Follow these workflows:**
- Workflow #23 ([Credential Rotation](../claude_workflows/workflow_descriptions/23_credential_rotation.md))
- Workflow #19 ([Backup & Recovery](../claude_workflows/workflow_descriptions/19_backup_recovery.md))

**Security checklist:**
- [ ] SSH key pair stored securely (not in repository)
- [ ] Security group restricts SSH to your IP only
- [ ] Database password in ~/.env (not hardcoded)
- [ ] ~/.env file permissions set to 600 (owner read/write only)
- [ ] Stop instance when not in use
- [ ] Regular AMI snapshots for backup

---

## Sub-4.0005: Temporal Event-Level Simulation (FUTURE ENHANCEMENT)

**Status:** ⏸️ PENDING
**Prerequisites:** 3.0005 complete (Temporal Database Schema), traditional simulation working
**Time Estimate:** 2-3 weeks
**Estimated Cost:** No additional cost (uses existing EC2)

### Overview

Enhance the simulation engine to operate at event-level temporal resolution instead of game-level aggregates. This enables realistic play-by-play simulation with timestamps, player fatigue modeling, and momentum effects.

**Traditional simulation:**
- Input: Team season averages (PPG, FG%, etc.)
- Output: Final score prediction
- Resolution: Game-level

**Temporal simulation:**
- Input: Player/team statistics + temporal events database
- Output: Complete play-by-play sequence with timestamps
- Resolution: Event-level (every shot, foul, turnover with precise timestamp)

### Temporal Features for Simulation

**1. Player Fatigue Modeling**
```python
def calculate_fatigue_factor(player_id, current_timestamp, game_start):
    """
    Calculate player fatigue based on minutes played and rest.

    Fatigue affects shooting percentage, turnovers, defensive efficiency.
    """
    minutes_played = get_player_minutes_at_time(player_id, current_timestamp)
    rest_since_last_sub = get_rest_duration(player_id, current_timestamp)

    # Fatigue increases with minutes, decreases with rest
    fatigue = 1.0 - (minutes_played / 48.0) * 0.3 + (rest_since_last_sub / 300.0) * 0.1
    return max(0.5, min(1.0, fatigue))  # Clamp between 50% and 100%

# Example: Player at 35 minutes with 2 minutes rest
# fatigue = 1.0 - (35/48)*0.3 + (120/300)*0.1 = 0.82 (18% fatigue penalty)
```

**2. Age-Based Performance Curves**
```python
def get_age_adjusted_stats(player_id, event_timestamp):
    """
    Adjust player statistics based on precise age at event time.

    Peak performance: ~27-29 years
    Decline rate: ~2% per year after age 30
    """
    age_years = calculate_player_age(player_id, event_timestamp)
    base_stats = get_player_career_averages(player_id)

    if age_years < 27:
        # Young player still improving
        age_factor = 0.85 + (age_years - 19) * 0.0188  # 85% at 19 → 100% at 27
    elif age_years <= 30:
        # Peak years
        age_factor = 1.0
    else:
        # Decline phase
        age_factor = 1.0 - (age_years - 30) * 0.02  # -2% per year

    return {k: v * age_factor for k, v in base_stats.items()}

# Example: Kobe at 37.8 years
# age_factor = 1.0 - (37.8 - 30) * 0.02 = 0.844 (15.6% decline from peak)
```

**3. Momentum & Clutch Effects**
```python
def calculate_momentum_factor(team_id, current_timestamp, lookback_seconds=300):
    """
    Calculate team momentum based on recent scoring runs.

    Momentum affects shooting confidence and turnover rates.
    """
    recent_events = get_team_events_in_window(
        team_id,
        current_timestamp - timedelta(seconds=lookback_seconds),
        current_timestamp
    )

    # Calculate scoring differential in last 5 minutes
    points_scored = sum(e.points for e in recent_events if e.event_type == 'shot' and e.made)
    points_allowed = get_opponent_points_in_window(team_id, current_timestamp, lookback_seconds)

    momentum = (points_scored - points_allowed) / 10.0  # Normalize
    return max(-0.1, min(0.1, momentum))  # +/-10% shooting boost

# Example: Team on 12-2 run in last 5 minutes
# momentum = (12 - 2) / 10 = +0.10 (+10% shooting boost)
```

**4. Clutch Time Adjustments**
```python
def is_clutch_situation(game_state, current_timestamp):
    """
    Detect clutch situations: close game, final 5 minutes.

    Some players perform better/worse in clutch.
    """
    if game_state.quarter < 4:
        return False

    game_clock_seconds = game_state.game_clock_seconds
    score_diff = abs(game_state.home_score - game_state.away_score)

    # Clutch: 4th quarter, < 5 minutes, score within 5 points
    return game_clock_seconds < 300 and score_diff <= 5

def get_clutch_factor(player_id):
    """
    Player-specific clutch performance multiplier.

    Calculated from historical clutch situations.
    """
    historical_clutch_stats = query_player_clutch_performance(player_id)
    regular_stats = query_player_regular_performance(player_id)

    # Ratio of clutch performance to regular performance
    return historical_clutch_stats.fg_pct / regular_stats.fg_pct

# Example: Kobe's clutch factor = 0.467 / 0.447 = 1.045 (+4.5% in clutch)
```

### Simulation Algorithm

**Event-Level Monte Carlo Simulation:**

```python
def simulate_game_temporal(home_team_id, away_team_id, game_date):
    """
    Simulate entire game at event-level with timestamps.
    """
    # Initialize game state
    game_state = GameState(
        home_team_id=home_team_id,
        away_team_id=away_team_id,
        game_date=game_date,
        current_time=game_date + timedelta(hours=19),  # 7 PM tip-off
        quarter=1,
        game_clock_seconds=720,  # 12 minutes
        home_score=0,
        away_score=0
    )

    simulated_events = []

    while game_state.quarter <= 4 or game_state.is_overtime:
        # Determine possession
        possession_team = determine_possession(game_state)

        # Simulate possession outcome
        event = simulate_possession(
            possession_team,
            game_state,
            simulated_events
        )

        # Update game state
        game_state.apply_event(event)

        # Advance clock (typical possession: 14-24 seconds)
        possession_duration = random.triangular(10, 24, 18)
        game_state.advance_clock(possession_duration)
        game_state.current_time += timedelta(seconds=possession_duration)

        # Store event with timestamp
        event.wall_clock_time = game_state.current_time
        event.game_clock_seconds = game_state.game_clock_seconds
        simulated_events.append(event)

        # Check for quarter end
        if game_state.game_clock_seconds <= 0:
            game_state.end_quarter()

    return simulated_events, game_state

def simulate_possession(team_id, game_state, event_history):
    """
    Simulate single possession outcome with temporal factors.
    """
    # Select shooter based on lineup and minutes played
    shooter = select_shooter(team_id, game_state)

    # Get player stats with temporal adjustments
    base_stats = get_player_snapshot_at_time(shooter.id, game_state.current_time)
    age_factor = get_age_adjusted_stats(shooter.id, game_state.current_time)
    fatigue_factor = calculate_fatigue_factor(shooter.id, game_state.current_time, game_state.game_start)
    momentum_factor = calculate_momentum_factor(team_id, game_state.current_time)

    # Adjust shooting percentage
    fg_pct = base_stats.fg_pct * age_factor * fatigue_factor * (1 + momentum_factor)

    # Check for clutch situation
    if is_clutch_situation(game_state, game_state.current_time):
        clutch_factor = get_clutch_factor(shooter.id)
        fg_pct *= clutch_factor

    # Simulate shot outcome
    shot_made = random.random() < fg_pct
    points = determine_shot_value(game_state)  # 2 or 3 points

    return Event(
        event_type='shot',
        player_id=shooter.id,
        team_id=team_id,
        made=shot_made,
        points=points if shot_made else 0,
        game_state=game_state.snapshot()
    )
```

### Benefits of Temporal Simulation

**1. Realistic Play-by-Play Sequences**
- Every event has a timestamp (wall clock + game clock)
- Can replay simulated games with exact timing
- Enables highlight generation: "Show me all 3-pointers made in Q4"

**2. Player Development Over Time**
- Simulate player aging effects within simulation
- Account for injuries, rest days, back-to-back games
- Model career arcs with temporal precision

**3. In-Game Adjustments**
- Coach substitutions based on fatigue
- Defensive adjustments in real-time
- Timeout impacts on momentum

**4. Advanced ML Features**
- Use simulated temporal data to train models
- Generate synthetic play-by-play for data augmentation
- Test "what-if" scenarios: "What if Kobe rested 2 more minutes?"

**5. Video Integration Readiness**
- Simulated events have timestamps compatible with video
- Can sync simulated plays with actual game footage
- Compare simulated vs. actual possession-by-possession

### Implementation Steps

**Week 1: Core Temporal Simulation**
1. ⏸️ Implement event-level simulation loop
2. ⏸️ Add timestamp tracking (wall clock + game clock)
3. ⏸️ Integrate with temporal_events table
4. ⏸️ Test with single game simulation

**Week 2: Temporal Feature Engineering**
1. ⏸️ Implement fatigue calculation
2. ⏸️ Implement age adjustment curves
3. ⏸️ Implement momentum tracking
4. ⏸️ Implement clutch detection and factors

**Week 3: Validation & Refinement**
1. ⏸️ Compare simulated vs. actual game timings
2. ⏸️ Validate player aging effects
3. ⏸️ Tune momentum and fatigue parameters
4. ⏸️ Performance testing (simulate 100 games)

### Example Output

**Simulated Play-by-Play with Timestamps:**
```
2016-06-19 19:02:22 | Q1 11:38 | Kobe Bryant 3PT shot MADE (3-0)
2016-06-19 19:02:38 | Q1 11:22 | Rudy Gobert 2PT shot MADE (3-2)
2016-06-19 19:02:54 | Q1 11:06 | Kobe Bryant 2PT shot MISSED
2016-06-19 19:03:10 | Q1 10:50 | Gordon Hayward 3PT shot MADE (3-5)
...
2016-06-19 21:45:34 | Q4 00:02 | Kobe Bryant FREE THROW MADE (59-103)
2016-06-19 21:45:38 | Q4 00:00 | GAME END (60-103)
```

**Player Statistics with Temporal Factors:**
```
Kobe Bryant - Age: 37.8 years
Minutes Played: 28:14
Fatigue Factor: 0.76 (24% fatigue at end)
Age Factor: 0.84 (16% decline from peak)
Clutch Factor: 1.05 (+5% in final 5 min)

Final Stats:
- 19/35 FG (54.3%)
- 4/12 3PT (33.3%)
- 18/20 FT (90.0%)
- 60 Points
```

### Validation Metrics

- [ ] Simulated possession duration matches actual (μ=18s, σ=6s)
- [ ] Simulated scoring pace matches actual (±5 points per game)
- [ ] Fatigue effects observable (shooting % decline in 4th quarter)
- [ ] Age effects match historical aging curves (R² > 0.85)
- [ ] Clutch performance differential matches historical (±2%)
- [ ] Momentum effects statistically significant (p < 0.05)

### Cost Impact

**No additional cost:**
- Uses existing EC2 instance
- Queries existing temporal_events table
- No new infrastructure needed

**Performance:**
- Traditional simulation: ~0.1 seconds per game
- Temporal simulation: ~2-5 seconds per game (20-50x slower)
- **Still practical:** Can simulate 100 games in 3-8 minutes

### See Also

- `docs/PROJECT_VISION.md` - Temporal panel data vision
- `docs/phases/PHASE_3_DATABASE.md` - Sub-3.0005 (Temporal Database Schema)
- `docs/ADVANCED_SIMULATION_FRAMEWORK.md` - Advanced econometric models (future)

---

## Navigation

**Return to:** [PROGRESS.md](../../PROGRESS.md) | **Workflows:** [Workflow Index](../claude_workflows/CLAUDE_WORKFLOW_ORDER.md)

**Related phases:**
- Previous: [Phase 3: Database Infrastructure](PHASE_3_DATABASE.md)
- Next: [Phase 5: Machine Learning](PHASE_5_MACHINE_LEARNING.md) (can run in parallel)

---

*For Claude Code: See CLAUDE.md for navigation instructions and context management strategies.*

---

*Last updated: 2025-10-07* (Added Sub-4.0005: Temporal Event-Level Simulation)
*Status: ✅ COMPLETE - Implementation successful*
*Actual implementation time: 3 hours*
