# hoopR 152 Endpoints - Complete NBA Stats API Scraper

**Created:** October 7, 2025
**Purpose:** Scrape ALL 152 hoopR NBA Stats API endpoints with production-ready error handling, CSV output, and S3 integration
**Location:** `scripts/etl/scrape_hoopr_all_152_endpoints.R`

---

## Overview

This scraper collects data from all 152 hoopR NBA Stats API endpoints using a 4-phase approach:

1. **Phase 1: Bulk Data Loaders** (4 endpoints) - Most efficient, save per-season
2. **Phase 2: Static/Reference Data** (25 endpoints) - One-time scrapes
3. **Phase 3: Per-Season Dashboards** (40 endpoints) - League-wide statistics
4. **Phase 4: Per-Game Boxscores** (87 endpoints) - Detailed game analysis

---

## Key Features

### ðŸ”’ Production-Ready Design

- **CSV Output** (not JSON) - Avoids R's 2GB string limit issue
- **Per-Season Saving** - Bulk loaders save individually to prevent memory overflow
- **Retry Logic** - 3 attempts per endpoint with exponential backoff
- **Rate Limiting** - 2.5 second delay between API calls
- **Automatic S3 Upload** - Optional real-time upload as files are created
- **Comprehensive Logging** - Timestamped logs with phase breakdowns
- **Process Management** - PID tracking, graceful shutdown, progress monitoring

### ðŸ“Š Complete Endpoint Coverage

**Phase 1: Bulk Data Loaders (4 endpoints)**
- `load_nba_pbp` - Play-by-play events
- `load_nba_player_box` - Player box scores
- `load_nba_team_box` - Team box scores
- `load_nba_schedule` - Game schedules

**Phase 2: Static/Reference Data (25 endpoints)**
- All-time leaders (`nba_alltimeleadersgrids`)
- Player index (`nba_commonallplayers`, `nba_playerindex`)
- Team info (`nba_teams`, `nba_franchisehistory`)
- Draft data (`nba_drafthistory`, `nba_draftcombine*`)
- Playoff series (`nba_commonplayoffseries`)
- Scoreboards (`nba_scoreboard`, `nba_scoreboardv2`, `nba_scoreboardv3`)
- Defense hub (`nba_defensehub`)
- Leaders (`nba_homepageleaders`, `nba_leagueleaders`, `nba_leaderstiles`)
- Franchise leaders (`nba_franchiseleaders`, `nba_franchiseleaderswrank`)

**Phase 3: Per-Season Dashboards (40 endpoints)**
- League player stats (`nba_leaguedashplayerstats`)
- League team stats (`nba_leaguedashteamstats`)
- Player bio stats (`nba_leaguedashplayerbiostats`)
- Clutch stats (player & team)
- Shot locations (player & team)
- Player tracking shots (`nba_leaguedashplayerptshot` - 2013+)
- Team tracking shots (`nba_leaguedashteamptshot` - 2013+)
- Lineups (`nba_leaguedashlineups`)
- Standings (`nba_leaguestandingsv3`)
- Hustle stats leaders
- Tracking stats leaders
- Defense dashboards

**Phase 4: Per-Game Boxscores (87 endpoints)**
- Traditional boxscores (v2 & v3)
- Advanced boxscores (v2 & v3)
- Scoring boxscores (v2 & v3)
- Usage boxscores (v2 & v3)
- Four factors boxscores (v2 & v3)
- Misc boxscores (v2 & v3)
- Tracking boxscores (v2 & v3)
- Hustle boxscores (v2)
- Matchups boxscores (v3)
- Defensive boxscores (v2)
- Shot charts (`nba_shotchartdetail`, `nba_shotchartleaguewide`, `nba_shotchartlineupdetail`)
- Synergy play types (`nba_synergyplaytypes`)
- Game rotation (`nba_gamerotation`)
- Assist tracker (`nba_assisttracker`)
- Player dashboards (clutch, shooting, splits, opponent, etc.)
- Team dashboards (clutch, shooting, splits, opponent, etc.)
- Player tracking (shots, rebounds, passing, defense)
- Team tracking (shots, rebounds, passing)
- Cumulative stats (player & team)
- Game logs (player & team)
- Game streaks (player & team)
- Player career stats
- Player profiles & awards
- Player vs player
- Team vs player
- Team details & historical leaders
- Video events

---

## Installation & Setup

### Prerequisites

**R Environment:**
```bash
# Install R (if not already installed)
# macOS:
brew install r

# Ubuntu/Debian:
sudo apt-get install r-base
```

**Required R Packages:**
```r
install.packages(c(
  "hoopR",      # NBA Stats API wrapper
  "dplyr",      # Data manipulation
  "readr",      # CSV reading/writing
  "purrr",      # Functional programming
  "lubridate",  # Date handling
  "stringr"     # String manipulation
))
```

**AWS CLI (for S3 upload):**
```bash
# macOS:
brew install awscli

# Configure credentials:
aws configure
```

### Verify Installation

```bash
# Check R version
Rscript --version

# Check R packages
Rscript -e "library(hoopR); library(dplyr); library(readr)"

# Check AWS CLI (if using S3)
aws --version
aws s3 ls s3://nba-sim-raw-data-lake/
```

---

## Usage

### Quick Start

**1. Basic Usage (All Seasons, No S3):**
```bash
# Default: 2002-2025, local storage only
bash scripts/etl/overnight_hoopr_all_152.sh
```

**2. Recent Seasons with S3 Upload:**
```bash
# Last 5 seasons (2020-2025) with S3 upload
bash scripts/etl/overnight_hoopr_all_152.sh "2020:2025" --upload-to-s3
```

**3. Single Season:**
```bash
# Just 2024 season
bash scripts/etl/overnight_hoopr_all_152.sh "2024:2024" --upload-to-s3
```

### Direct R Script Usage

```bash
# Run R script directly
Rscript scripts/etl/scrape_hoopr_all_152_endpoints.R \
  /tmp/hoopr_all_152 \
  --seasons=2020:2025 \
  --upload-to-s3
```

### Command-Line Arguments

**Shell Wrapper (`overnight_hoopr_all_152.sh`):**
- **Argument 1:** Season range (e.g., `2020:2025`, `2024:2024`)
- **Argument 2:** S3 upload flag (`--upload-to-s3`)

**R Script (`scrape_hoopr_all_152_endpoints.R`):**
- **Argument 1:** Output directory (default: `/tmp/hoopr_all_152`)
- **Flag:** `--upload-to-s3` - Enable S3 upload
- **Flag:** `--seasons=START:END` - Season range (default: `2002:2025`)

---

## Monitoring & Management

### Process Monitoring

**Check if running:**
```bash
# Check PID file
cat /tmp/hoopr_all_152.pid

# Check process
ps aux | grep scrape_hoopr_all_152

# Or check via PID
ps -p $(cat /tmp/hoopr_all_152.pid)
```

**View live log:**
```bash
# Follow log in real-time
tail -f /tmp/hoopr_all_152_overnight.log

# Last 100 lines
tail -100 /tmp/hoopr_all_152_overnight.log

# Search for errors
grep ERROR /tmp/hoopr_all_152_overnight.log
grep WARN /tmp/hoopr_all_152_overnight.log
```

**Check progress:**
```bash
# Count CSV files created
find /tmp/hoopr_all_152 -name "*.csv" | wc -l

# Directory sizes
du -sh /tmp/hoopr_all_152/*

# Total size
du -sh /tmp/hoopr_all_152

# Files per category
ls -lh /tmp/hoopr_all_152/*/
```

### Process Control

**Stop gracefully:**
```bash
# Send SIGTERM (graceful shutdown)
kill $(cat /tmp/hoopr_all_152.pid)
```

**Force kill:**
```bash
# Send SIGKILL (immediate stop)
kill -9 $(cat /tmp/hoopr_all_152.pid)
```

**Clean up after failure:**
```bash
# Remove PID file if stale
rm -f /tmp/hoopr_all_152.pid

# Clear output and start fresh
rm -rf /tmp/hoopr_all_152/*
```

---

## Output Structure

### Directory Layout

```
/tmp/hoopr_all_152/
â”œâ”€â”€ bulk_pbp/                    # Phase 1: Play-by-play
â”‚   â”œâ”€â”€ pbp_2002.csv
â”‚   â”œâ”€â”€ pbp_2003.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ bulk_player_box/             # Phase 1: Player box scores
â”‚   â”œâ”€â”€ player_box_2002.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ bulk_team_box/               # Phase 1: Team box scores
â”‚   â”œâ”€â”€ team_box_2002.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ bulk_schedule/               # Phase 1: Schedules
â”‚   â”œâ”€â”€ schedule_2002.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ static_data/                 # Phase 2: Static endpoints
â”‚   â”œâ”€â”€ all_time_leaders.csv
â”‚   â”œâ”€â”€ league_leaders_2025.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ player_info/                 # Phase 2: Player reference
â”‚   â”œâ”€â”€ all_players.csv
â”‚   â”œâ”€â”€ player_index.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ team_info/                   # Phase 2: Team reference
â”‚   â”œâ”€â”€ teams.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ draft/                       # Phase 2: Draft data
â”‚   â”œâ”€â”€ draft_history_2024.csv
â”‚   â”œâ”€â”€ draft_combine_stats_2024.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ franchise/                   # Phase 2: Franchise data
â”‚   â”œâ”€â”€ franchise_history.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ league_dashboards/           # Phase 3: Per-season dashboards
â”‚   â”œâ”€â”€ player_stats_2024.csv
â”‚   â”œâ”€â”€ team_stats_2024.csv
â”‚   â”œâ”€â”€ player_clutch_2024.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ lineups/                     # Phase 3: 5-man lineups
â”‚   â”œâ”€â”€ lineups_5man_2024.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ standings/                   # Phase 3: Standings
â”‚   â”œâ”€â”€ standings_2024.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ boxscore_traditional/        # Phase 4: Traditional boxscores
â”‚   â”œâ”€â”€ game_0022400001.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ boxscore_advanced/           # Phase 4: Advanced boxscores
â”‚   â””â”€â”€ ...
â”œâ”€â”€ boxscore_scoring/            # Phase 4: Scoring boxscores
â”‚   â””â”€â”€ ...
â”œâ”€â”€ boxscore_tracking/           # Phase 4: Tracking boxscores
â”‚   â””â”€â”€ ...
â””â”€â”€ scraper_log_20251007_200000.txt  # Comprehensive log
```

### CSV File Format

**Standard Structure:**
- Each endpoint returns 1+ CSV files
- Multi-table endpoints create multiple files (e.g., `endpoint_table_1.csv`, `endpoint_table_2.csv`)
- File naming: `{category}_{identifier}.csv`
  - Bulk: `pbp_2024.csv`
  - Per-season: `player_stats_2024.csv`
  - Per-game: `game_0022400001.csv`

**Column Handling:**
- All columns preserved from API response
- No column filtering or transformation
- Raw data ready for downstream processing

---

## Performance & Runtime Estimates

### API Call Breakdown

**For 24 seasons (2002-2025):**

| Phase | Endpoints | Calls | Time @ 2.5s | Notes |
|-------|-----------|-------|-------------|-------|
| Phase 1 | 4 | 96 | 4 min | Per-season (4 Ã— 24) |
| Phase 2 | 25 | ~50 | 2 min | Static + draft years |
| Phase 3 | 40 | 960 | 40 min | Per-season (40 Ã— 24) |
| Phase 4 | 87 | ~30,000 | 21 hrs | Per-game (sample in script) |
| **Total** | **152** | **~31,106** | **~22 hrs** | Full implementation |

**Optimized Runtime (Phases 1-3 only):**
- **Total calls:** ~1,106
- **Runtime:** ~45-60 minutes
- **Output:** Core datasets for ML/simulation

**Full Runtime (All phases):**
- **Total calls:** ~31,106
- **Runtime:** ~20-24 hours
- **Output:** Complete granular data

### Storage Requirements

**Estimated Output Sizes (24 seasons):**

| Category | Files | Size | Notes |
|----------|-------|------|-------|
| Phase 1 (Bulk) | 96 | 8-12 GB | Play-by-play is largest |
| Phase 2 (Static) | 50 | 500 MB | Reference data |
| Phase 3 (Dashboards) | 960 | 2-4 GB | Per-season stats |
| Phase 4 (Boxscores) | ~30,000 | 10-15 GB | Per-game granular |
| **Total** | **~31,106** | **20-32 GB** | All endpoints |

**Disk Space Recommendations:**
- **Minimum:** 25 GB free in `/tmp`
- **Recommended:** 50 GB (allows for retries/backups)
- **S3 Cost:** ~$0.46-0.74/month (20-32 GB @ $0.023/GB)

---

## Error Handling & Recovery

### Built-in Error Handling

**Retry Logic:**
- **Max retries:** 3 attempts per endpoint
- **Delay:** 2.5 seconds between attempts
- **Exponential backoff:** Not implemented (fixed delay)

**Error Scenarios:**
1. **API timeout** â†’ Retry with same parameters
2. **Rate limit** â†’ Retry after delay
3. **Invalid game ID** â†’ Log error, continue to next
4. **Network failure** â†’ Retry, then fail gracefully
5. **Empty response** â†’ Log warning, save empty file (optional)

### Manual Recovery

**If scraper crashes mid-run:**

1. **Check what was completed:**
```bash
# Count files per category
ls -lR /tmp/hoopr_all_152 | grep "^-" | wc -l

# Check last log entry
tail -50 /tmp/hoopr_all_152_overnight.log
```

2. **Resume from failed season:**
```bash
# If failed at 2015, resume from there
bash scripts/etl/overnight_hoopr_all_152.sh "2015:2025" --upload-to-s3
```

3. **Re-run specific phase:**
```r
# Edit R script to skip completed phases
# Comment out Phase 1-2, run only Phase 3-4
```

**If API errors persist:**

1. **Check NBA Stats API status:**
   - Visit: https://stats.nba.com
   - Verify API is operational

2. **Check rate limiting:**
   - Increase `RATE_LIMIT_SECONDS` in R script
   - Change from 2.5s to 3-5s

3. **Reduce scope:**
   - Run fewer seasons at once
   - Skip problematic endpoints

---

## Data Validation

### Quality Checks

**After scraping completes:**

```bash
# 1. Verify file counts
find /tmp/hoopr_all_152 -name "*.csv" | wc -l
# Expected: ~1,100 files (Phases 1-3 for 24 seasons)

# 2. Check for empty files
find /tmp/hoopr_all_152 -name "*.csv" -size 0

# 3. Check total size
du -sh /tmp/hoopr_all_152
# Expected: 8-15 GB (Phases 1-3)

# 4. Verify season coverage
ls /tmp/hoopr_all_152/bulk_pbp/ | wc -l
# Expected: 24 files (one per season)
```

**R validation script:**
```r
library(readr)
library(dplyr)

# Load and validate bulk play-by-play
files <- list.files("/tmp/hoopr_all_152/bulk_pbp", full.names = TRUE)
for (f in files) {
  data <- read_csv(f, show_col_types = FALSE)
  cat(basename(f), ":", nrow(data), "rows,", ncol(data), "columns\n")

  # Check for required columns
  required_cols <- c("game_id", "event_type", "description")
  missing <- setdiff(required_cols, names(data))
  if (length(missing) > 0) {
    cat("  WARNING: Missing columns:", paste(missing, collapse = ", "), "\n")
  }
}
```

### S3 Upload Verification

**If S3 upload enabled:**

```bash
# 1. Count S3 objects
aws s3 ls s3://nba-sim-raw-data-lake/hoopr_152/ --recursive | wc -l

# 2. Compare local vs S3
LOCAL_COUNT=$(find /tmp/hoopr_all_152 -name "*.csv" | wc -l)
S3_COUNT=$(aws s3 ls s3://nba-sim-raw-data-lake/hoopr_152/ --recursive --summarize | grep "Total Objects" | awk '{print $3}')
echo "Local: $LOCAL_COUNT | S3: $S3_COUNT"

# 3. Check S3 size
aws s3 ls s3://nba-sim-raw-data-lake/hoopr_152/ --recursive --summarize | grep "Total Size"

# 4. Verify specific file
aws s3 ls s3://nba-sim-raw-data-lake/hoopr_152/bulk_pbp/pbp_2024.csv
```

---

## Integration with NBA Simulator

### Loading into PostgreSQL

**Bulk load play-by-play:**
```sql
-- Create staging table
CREATE TABLE staging.hoopr_pbp (
  game_id VARCHAR(50),
  event_num INTEGER,
  event_type VARCHAR(100),
  description TEXT,
  -- Add all columns from CSV
  CONSTRAINT pk_hoopr_pbp PRIMARY KEY (game_id, event_num)
);

-- Load from CSV
\COPY staging.hoopr_pbp FROM '/tmp/hoopr_all_152/bulk_pbp/pbp_2024.csv' WITH CSV HEADER;

-- Verify
SELECT COUNT(*), MIN(game_id), MAX(game_id) FROM staging.hoopr_pbp;
```

**Join with existing data:**
```sql
-- Enrich ESPN play-by-play with hoopR tracking data
SELECT
  e.game_id,
  e.play_description,
  h.event_type,
  h.player_id,
  h.team_id
FROM play_by_play e
INNER JOIN staging.hoopr_pbp h
  ON e.game_id = h.game_id
  AND e.sequence_number = h.event_num
WHERE e.game_date >= '2024-01-01';
```

### Feature Engineering Pipeline

**Extract advanced metrics:**
```python
import pandas as pd
import glob

# Load all player box scores
files = glob.glob('/tmp/hoopr_all_152/bulk_player_box/*.csv')
player_box = pd.concat([pd.read_csv(f) for f in files])

# Calculate True Shooting %
player_box['ts_pct'] = (
    player_box['points'] /
    (2 * (player_box['fga'] + 0.44 * player_box['fta']))
)

# Calculate usage rate
player_box['usg_pct'] = (
    100 * ((player_box['fga'] + 0.44 * player_box['fta'] + player_box['turnovers']) *
           (player_box['team_minutes'] / 5)) /
    (player_box['minutes'] * (player_box['team_fga'] + 0.44 * player_box['team_fta'] +
                               player_box['team_turnovers']))
)

# Save enriched dataset
player_box.to_csv('/tmp/hoopr_all_152/enriched/player_advanced_stats.csv', index=False)
```

### ML Model Integration

**Create feature vectors:**
```python
import pandas as pd
from sklearn.model_selection import train_test_split

# Load multiple data sources
pbp = pd.read_csv('/tmp/hoopr_all_152/bulk_pbp/pbp_2024.csv')
player_box = pd.read_csv('/tmp/hoopr_all_152/bulk_player_box/player_box_2024.csv')
lineups = pd.read_csv('/tmp/hoopr_all_152/lineups/lineups_5man_2024.csv')

# Merge on game_id
features = pbp.merge(player_box, on='game_id')
features = features.merge(lineups, on='game_id')

# Create target variable (e.g., win/loss)
features['target'] = (features['score_home'] > features['score_away']).astype(int)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    features.drop('target', axis=1),
    features['target'],
    test_size=0.2,
    random_state=42
)
```

---

## Troubleshooting

### Common Issues

**1. R package installation fails:**
```bash
# Install dependencies first
brew install openssl libxml2  # macOS
sudo apt-get install libssl-dev libxml2-dev  # Ubuntu

# Then install R packages
Rscript -e "install.packages('hoopR', repos='https://cloud.r-project.org')"
```

**2. Memory errors (R crashes):**
```r
# Reduce batch size in R script
# Change from all seasons to chunks:
SEASONS <- 2020:2022  # Process 3 years at a time

# Or increase R memory limit:
options(java.parameters = "-Xmx8g")  # 8GB
```

**3. S3 upload permission denied:**
```bash
# Check AWS credentials
aws sts get-caller-identity

# Verify bucket permissions
aws s3api get-bucket-policy --bucket nba-sim-raw-data-lake

# Test write access
echo "test" | aws s3 cp - s3://nba-sim-raw-data-lake/hoopr_152/test.txt
```

**4. API rate limiting:**
```r
# Increase delay in R script
RATE_LIMIT_SECONDS <- 5  # Change from 2.5 to 5 seconds
```

**5. Stale PID file:**
```bash
# Remove and restart
rm -f /tmp/hoopr_all_152.pid
bash scripts/etl/overnight_hoopr_all_152.sh
```

### Debug Mode

**Enable verbose logging:**
```r
# Add to R script (top of file)
options(warn = 1)  # Print warnings immediately
options(error = recover)  # Debug on error
```

**Check specific endpoint:**
```r
# Test single endpoint
library(hoopR)
data <- nba_leaguedashplayerstats(season = "2024-25", per_mode = "PerGame")
print(head(data))
```

---

## Advanced Configuration

### Custom Season Ranges

**Process only recent seasons:**
```bash
# Last 3 years
bash scripts/etl/overnight_hoopr_all_152.sh "2022:2025" --upload-to-s3
```

**Process by decade:**
```bash
# 2000s
bash scripts/etl/overnight_hoopr_all_152.sh "2000:2009" --upload-to-s3

# 2010s
bash scripts/etl/overnight_hoopr_all_152.sh "2010:2019" --upload-to-s3
```

### Skip Phases

**Modify R script to skip completed phases:**
```r
# Comment out Phase 1 if already done
# cat("\n", rep("=", 80), "\n", sep = "")
# cat("PHASE 1: BULK DATA LOADERS (Per-Season Saving)\n")
# ... (comment out entire Phase 1 block)

# Run only Phase 3
# (uncomment only Phase 3 section)
```

### Parallel Processing (Advanced)

**Run multiple season ranges in parallel:**
```bash
# Terminal 1: 2002-2010
bash scripts/etl/overnight_hoopr_all_152.sh "2002:2010" --upload-to-s3 &

# Terminal 2: 2011-2019
bash scripts/etl/overnight_hoopr_all_152.sh "2011:2019" --upload-to-s3 &

# Terminal 3: 2020-2025
bash scripts/etl/overnight_hoopr_all_152.sh "2020:2025" --upload-to-s3 &

# Monitor all
tail -f /tmp/hoopr_all_152_overnight.log
```

**Note:** Ensure output directories don't conflict by modifying OUTPUT_DIR.

---

## Cost Analysis

### S3 Storage Costs

**Monthly costs (24 seasons, all phases):**
- **Storage:** 25 GB Ã— $0.023/GB = **$0.58/month**
- **PUT requests:** 31,106 Ã— $0.005/1000 = **$0.16**
- **GET requests:** Minimal (one-time download)
- **Data transfer:** Free (within AWS region)

**Total first month:** ~$0.74
**Ongoing monthly:** ~$0.58

### Data Transfer Costs

**S3 to RDS (same region):** Free
**S3 to local (egress):**
- First 100 GB/month: Free
- Our data: 25 GB (free)

**Total egress cost:** $0

---

## Maintenance & Updates

### Weekly Tasks

1. **Check scraper status:**
```bash
ps aux | grep scrape_hoopr_all_152
```

2. **Verify S3 uploads:**
```bash
aws s3 ls s3://nba-sim-raw-data-lake/hoopr_152/ --recursive --summarize
```

3. **Clean old logs:**
```bash
# Keep only last 7 days
find /tmp -name "hoopr_all_152_overnight*.log" -mtime +7 -delete
```

### Monthly Tasks

1. **Update hoopR package:**
```r
update.packages("hoopR")
```

2. **Re-scrape current season:**
```bash
CURRENT_SEASON=$(date +%Y)
bash scripts/etl/overnight_hoopr_all_152.sh "$CURRENT_SEASON:$CURRENT_SEASON" --upload-to-s3
```

3. **Archive old data:**
```bash
# Move to Glacier for long-term storage
aws s3 sync s3://nba-sim-raw-data-lake/hoopr_152/ \
  s3://nba-sim-archives/hoopr_152/ \
  --storage-class GLACIER
```

---

## Future Enhancements

### Planned Features

1. **Incremental updates:**
   - Check existing files, skip if already scraped
   - Only fetch new games since last run

2. **Advanced retry logic:**
   - Exponential backoff
   - Per-endpoint retry configurations
   - Dead letter queue for failed endpoints

3. **Data validation:**
   - Schema validation against expected structure
   - Row count checks (expected vs actual)
   - Automated quality reports

4. **Performance optimization:**
   - Parallel endpoint fetching (where safe)
   - Batch S3 uploads (vs per-file)
   - Compressed CSV output (gzip)

5. **Monitoring & Alerts:**
   - CloudWatch metrics integration
   - SNS notifications on completion/failure
   - Progress dashboard (web UI)

---

## Related Documentation

- **Main scraper:** `scripts/etl/scrape_hoopr_all_152_endpoints.R`
- **Wrapper script:** `scripts/etl/overnight_hoopr_all_152.sh`
- **hoopR documentation:** https://hoopr.sportsdataverse.org/
- **NBA Stats API:** https://stats.nba.com
- **Project setup:** `docs/SETUP.md`
- **Data structure:** `docs/DATA_STRUCTURE_GUIDE.md`

---

## Support & Contact

**Issues:**
- Check troubleshooting section above
- Review log files for error details
- Test individual endpoints in R console

**Questions:**
- Review hoopR documentation
- Check NBA Stats API status
- Consult project documentation in `docs/`

---

*Last updated: October 7, 2025*
*Version: 1.0*
*Maintainer: NBA Simulator Project*
